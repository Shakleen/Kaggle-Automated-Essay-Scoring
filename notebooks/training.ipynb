{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‹ï¸ Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“š Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing from packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing user defined packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.config import config\n",
    "from lib.paths import Paths\n",
    "from lib.model.deberta import CustomModel\n",
    "from lib.model.epoch_functions import train_epoch, valid_epoch\n",
    "from lib.model.utils import get_score\n",
    "from lib.utils.utils import get_logger, seed_everything\n",
    "from lib.data import read_data_loader_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“– Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒŽ Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = get_logger(Paths.MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ› ï¸ Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p\n",
    "                for n, p in model.model.named_parameters()\n",
    "                if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"lr\": encoder_lr,\n",
    "            \"weight_decay\": weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p\n",
    "                for n, p in model.model.named_parameters()\n",
    "                if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"lr\": encoder_lr,\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "            \"lr\": decoder_lr,\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return optimizer_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, num_train_steps):\n",
    "    if config.scheduler == \"linear\":\n",
    "        return get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=config.num_warmup_steps,\n",
    "            num_training_steps=num_train_steps,\n",
    "        )\n",
    "\n",
    "    if config.scheduler == \"cosine\":\n",
    "        return get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=config.num_warmup_steps,\n",
    "            num_training_steps=num_train_steps,\n",
    "            num_cycles=config.num_cycles,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_optimizer_and_scheduler(train_loader):\n",
    "    model = CustomModel(config, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, Paths.MODEL_OUTPUT_PATH + \"/config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        get_optimizer_params(\n",
    "            model,\n",
    "            encoder_lr=config.encoder_lr,\n",
    "            decoder_lr=config.decoder_lr,\n",
    "            weight_decay=config.weight_decay,\n",
    "        ),\n",
    "        lr=config.encoder_lr,\n",
    "        eps=config.eps,\n",
    "        betas=config.betas,\n",
    "    )\n",
    "\n",
    "    num_train_steps = int(len(train_loader) / config.batch_size_train * config.epochs)\n",
    "    scheduler = get_scheduler(optimizer, num_train_steps)\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(fold):\n",
    "    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n",
    "\n",
    "    # ======== DATA LOADER ==========\n",
    "    train_loader, valid_loader = read_data_loader_from_disk(fold)\n",
    "    valid_fold = pd.read_csv(os.path.join(Paths.DATA_LOADER_PATH, f\"valid_{fold}.csv\"))\n",
    "    valid_labels = valid_fold[\"score\"].values\n",
    "\n",
    "    # ======== MODEL ==========\n",
    "    model, optimizer, scheduler = get_model_optimizer_and_scheduler(train_loader)\n",
    "\n",
    "    # ======= LOSS ==========\n",
    "    # criterion = RMSELoss(reduction=\"mean\") # nn.SmoothL1Loss(reduction='mean')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    best_score = -np.inf\n",
    "    # ====== ITERATE EPOCHS ========\n",
    "    for epoch in range(config.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ======= TRAIN ==========\n",
    "        avg_loss = train_epoch(\n",
    "            train_loader, model, criterion, optimizer, epoch, scheduler, device\n",
    "        )\n",
    "\n",
    "        # ======= EVALUATION ==========\n",
    "        avg_val_loss, prediction_dict = valid_epoch(\n",
    "            valid_loader, model, criterion, device\n",
    "        )\n",
    "        predictions = prediction_dict[\"predictions\"]\n",
    "        _, predictions = torch.max(softmax(torch.tensor(predictions)), dim=1)\n",
    "\n",
    "        # ======= SCORING ==========\n",
    "        score = get_score(valid_labels, predictions)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "        )\n",
    "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
    "            torch.save(\n",
    "                {\"model\": model.state_dict(), \"predictions\": predictions},\n",
    "                Paths.MODEL_OUTPUT_PATH\n",
    "                + f\"/{config.model.replace('/', '_')}_fold_{fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        Paths.MODEL_OUTPUT_PATH\n",
    "        + f\"/{config.model.replace('/', '_')}_fold_{fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    valid_fold[\"pred_score\"] = predictions\n",
    "\n",
    "    del model, optimizer, scheduler, criterion, softmax\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return valid_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(oof_df):\n",
    "    labels = oof_df[\"score\"].values\n",
    "    preds = oof_df[\"pred_score\"].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f'Score: {score:<.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.train:\n",
    "    oof_df = pd.DataFrame()\n",
    "\n",
    "    for fold in range(config.n_folds):\n",
    "        if fold in config.train_folds:\n",
    "            _oof_df = train_loop(fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== Fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "\n",
    "    oof_df = oof_df.reset_index(drop=True)\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    get_result(oof_df)\n",
    "    oof_df.to_csv(Paths.MODEL_OUTPUT_PATH + \"/oof_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ó HuggingFace Neural Network Notebook - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0\n",
    "Copied from CV Split training notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Tuple, List\n",
    "import warnings\n",
    "import pickle as pkl\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tokenizers import AddedToken\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    cohen_kappa_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../../\")\n",
    "warnings.simplefilter('ignore')\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.criterion.metrics import log_metrics\n",
    "from lib.utils.find_threshold import find_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paths:\n",
    "    # Competition data with added topic column\n",
    "    train_csv: str = \"data/processed/train.csv\"\n",
    "    test_csv: str = \"data/processed/test.csv\"\n",
    "\n",
    "    # Output path\n",
    "    output_path: str = \"output/model_dir_ht\"\n",
    "    model_path: str = os.path.join(output_path, \"{model_name}\")\n",
    "    tokenizer_path: str =  os.path.join(model_path, \"{model_name}_tokenizer\")\n",
    "    threshold_path: str = os.path.join(model_path, \"threshold.pkl\")\n",
    "    logging_path: str = os.path.join(model_path, \"logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "DO_SLIDING_WINDOW = True\n",
    "DO_REGRESSION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    backbone_model: str = 'microsoft/deberta-v3-xsmall'\n",
    "    max_length: int = 512\n",
    "    num_labels: int = 6\n",
    "    num_workers: int = 6\n",
    "    seed: int = 20\n",
    "    stride_length: int = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    CFG.num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = CFG.backbone_model.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything() -> None:\n",
    "    \"\"\"Seed everything to ensure reproducibility\n",
    "\n",
    "    Sources:\n",
    "    1. https://www.kaggle.com/code/alejopaullier/aes-2-multi-class-classification-train\n",
    "    2. https://www.kaggle.com/code/hashidoyuto/deberta-baseline-aes2-0-train\n",
    "    \"\"\"\n",
    "    random.seed(CFG.seed)\n",
    "    os.environ[\"PYTHONHASHCFG.SEED\"] = str(CFG.seed)\n",
    "    np.random.seed(CFG.seed)\n",
    "    torch.manual_seed(CFG.seed)\n",
    "    torch.cuda.manual_seed(CFG.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    # How to perform hyperparameter tuning\n",
    "    \"method\": \"random\",\n",
    "    # How to evaluate which hyperparameter combination is good\n",
    "    \"metric\": {\n",
    "        \"name\": \"QWK\",\n",
    "        \"goal\": \"maximize\",\n",
    "    },\n",
    "    # Hyperparameters to tune\n",
    "    \"parameters\": {\n",
    "        # Hyperparameters that will change\n",
    "        \"lr\": {\"distribution\": \"uniform\", \"min\": 1e-5, \"max\": 1e-3},\n",
    "        \"weight_decay\": {\"distribution\": \"uniform\", \"min\": 0.01, \"max\": 0.1},\n",
    "        \"num_epochs\": {\"values\": [3, 4, 5]},\n",
    "        \"warmup_ratio\": {\"distribution\": \"uniform\", \"min\": 0.01, \"max\": 0.1},\n",
    "        \"lr_scheduler_type\": {\"values\": [\"cosine\", \"linear\"]},\n",
    "        \"batch_size\": {\"values\": [8, 16, 32]},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WandB setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"Kaggle_ASE_2.0\"\n",
    "EXPERIMENT = f\"ASE-sweep-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshakleenishfar\u001b[0m (\u001b[33mlaplacesdemon43\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ishfar/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: norrpezc\n",
      "Sweep URL: https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key=os.environ.get('WANDB_API_KEY'))\n",
    "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    def __init__(self, train, valid, test, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.test = test\n",
    "\n",
    "    def get_dataset(self, df):\n",
    "        ds = Dataset.from_dict(\n",
    "            {\n",
    "                \"essay_id\": [e for e in df[\"essay_id\"]],\n",
    "                \"full_text\": [ft for ft in df[\"full_text\"]],\n",
    "                \"label\": [s for s in df[\"label\"]],\n",
    "            }\n",
    "        )\n",
    "        return ds\n",
    "\n",
    "    def tokenize_function(self, example):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            example[\"full_text\"],\n",
    "            truncation=True,\n",
    "            max_length=CFG.max_length,\n",
    "            padding=\"max_length\",\n",
    "            \n",
    "        )\n",
    "        return tokenized_inputs\n",
    "\n",
    "    def __call__(self):\n",
    "        train_ds = self.get_dataset(self.train)\n",
    "        valid_ds = self.get_dataset(self.valid)\n",
    "        test_ds = self.get_dataset(self.test)\n",
    "\n",
    "        tokenized_train = train_ds.map(self.tokenize_function, batched=True)\n",
    "        tokenized_valid = valid_ds.map(self.tokenize_function, batched=True)\n",
    "        tokenized_test = test_ds.map(self.tokenize_function, batched=True)\n",
    "\n",
    "        return tokenized_train, tokenized_valid, tokenized_test, self.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('output/model_dir_ht/deberta-v3-xsmall/deberta-v3-xsmall_tokenizer/tokenizer_config.json',\n",
       " 'output/model_dir_ht/deberta-v3-xsmall/deberta-v3-xsmall_tokenizer/special_tokens_map.json',\n",
       " 'output/model_dir_ht/deberta-v3-xsmall/deberta-v3-xsmall_tokenizer/spm.model',\n",
       " 'output/model_dir_ht/deberta-v3-xsmall/deberta-v3-xsmall_tokenizer/added_tokens.json',\n",
       " 'output/model_dir_ht/deberta-v3-xsmall/deberta-v3-xsmall_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.backbone_model)\n",
    "tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "tokenizer.add_tokens([AddedToken(\" \" * 2, normalized=False)])\n",
    "tokenizer.save_pretrained(Paths.tokenizer_path.format(model_name=MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "1. Convert `label` to be in `scores` which are processed to be in range $[0-5]$.\n",
    "2. Convert `label` data type based on whether we are doing regression or classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset has shape: (17307, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  topic  \\\n",
       "0  000d118  Many people have car where they live. The thin...      3      5   \n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3      3   \n",
       "2  001ab80  People always wish they had the same technolog...      4      0   \n",
       "\n",
       "   label  \n",
       "0    2.0  \n",
       "1    2.0  \n",
       "2    3.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(Paths.train_csv, low_memory=False)\n",
    "print(\"Training dataset has shape:\", data.shape)\n",
    "\n",
    "data[\"label\"] = data[\"score\"].map(lambda x: x- 1)\n",
    "\n",
    "if DO_REGRESSION:\n",
    "    data[\"label\"] = data[\"label\"].astype(pd.Float32Dtype())\n",
    "else:\n",
    "    data[\"label\"] = data[\"label\"].astype(pd.Int32Dtype())\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Valid-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of train, valid and test data: (3461, 5) (1558, 5) (1731, 5)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data  = train_test_split(\n",
    "    data,\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    stratify=data[\"label\"],\n",
    "    random_state=CFG.seed,\n",
    ")\n",
    "train_data, valid_data  = train_test_split(\n",
    "    train_data,\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    stratify=train_data[\"label\"],\n",
    "    random_state=CFG.seed,\n",
    ")\n",
    "\n",
    "# Only use 20% of training dataset ofr hyper parameter tuning\n",
    "train_data, _ = train_test_split(\n",
    "    data,\n",
    "    test_size=0.8,\n",
    "    shuffle=True,\n",
    "    stratify=data[\"label\"],\n",
    "    random_state=CFG.seed,\n",
    ")\n",
    "\n",
    "print(\"Shapes of train, valid and test data:\", train_data.shape, valid_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window\n",
    "\n",
    "Essays can have varying lengths. Instead of truncating, see the entire essay as windows of length `CFG.max_length` which are strided with `CFG.stride_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_new_row(old_row, text):\n",
    "    new_row = {key: old_row[key] for key in old_row.keys() if key != \"index\"}\n",
    "    new_row[\"full_text\"] = text\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens(tokens, stride):\n",
    "    \"\"\"Splits `tokens` into multiple sequences that have at most\n",
    "    `CFG.max_length` tokens. Uses `CFG.stride` for sliding\n",
    "    window.\n",
    "\n",
    "    Args:\n",
    "        tokens (List): List of tokens.\n",
    "        stride (int): Stride length.\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: List of split token sequences.\n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    sequence_list = []\n",
    "\n",
    "    while start < len(tokens):\n",
    "        remaining_tokens = len(tokens) - start\n",
    "\n",
    "        if remaining_tokens < CFG.max_length and start > 0:\n",
    "            start = max(0, len(tokens) - CFG.max_length)\n",
    "\n",
    "        end = min(start + CFG.max_length, len(tokens))\n",
    "        sequence_list.append(tokens[start:end])\n",
    "\n",
    "        if remaining_tokens >= CFG.max_length:\n",
    "            start += stride\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, tokenizer):\n",
    "    \"\"\"Splits rows of `df` so that each row's text has at most\n",
    "    `CFG.max_length` number of tokens.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input data frame.\n",
    "        tokenizer (_type_): Tokenizer used to encode and decode text.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Newly constructed dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        tokens = tokenizer.encode(row[\"full_text\"], add_special_tokens=False)\n",
    "\n",
    "        if len(tokens) <= CFG.max_length:\n",
    "            new_df.append(construct_new_row(row, row[\"full_text\"]))\n",
    "        else:\n",
    "            sequence_list = split_tokens(tokens, CFG.stride_length)\n",
    "\n",
    "            for seq in sequence_list:\n",
    "                new_df.append(\n",
    "                    construct_new_row(\n",
    "                        row,\n",
    "                        tokenizer.decode(seq, skip_special_tokens=True),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3461/3461 [00:06<00:00, 569.83it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1558/1558 [00:02<00:00, 576.64it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1731/1731 [00:03<00:00, 571.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of train, valid and test data: (4568, 5) (2054, 5) (2267, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if DO_SLIDING_WINDOW:\n",
    "    train_data = sliding_window(train_data, tokenizer)\n",
    "    valid_data = sliding_window(valid_data, tokenizer)\n",
    "    test_data = sliding_window(test_data, tokenizer)\n",
    "    print(\"Shapes of train, valid and test data:\", train_data.shape, valid_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QWK Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_regression(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    qwk = cohen_kappa_score(\n",
    "        labels,\n",
    "        predictions.clip(0, 5).round(0),\n",
    "        weights=\"quadratic\",\n",
    "    )\n",
    "\n",
    "    return {\"qwk\": qwk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_classification(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    qwk = cohen_kappa_score(\n",
    "        labels,\n",
    "        predictions.argmax(-1),\n",
    "        weights=\"quadratic\",\n",
    "    )\n",
    "    \n",
    "    return {\"qwk\": qwk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_REGRESSION:\n",
    "    compute_metrics = compute_metrics_for_regression\n",
    "else:\n",
    "    compute_metrics = compute_metrics_for_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(\n",
    "    train: pd.DataFrame,\n",
    "    valid: pd.DataFrame,\n",
    "    test: pd.DataFrame,\n",
    ") -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    tokenize = Tokenize(train, valid, test, tokenizer)\n",
    "    tokenized_train, tokenized_valid, tokenized_test, _ = tokenize()\n",
    "    return tokenized_train, tokenized_valid, tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure():\n",
    "    config = AutoConfig.from_pretrained(CFG.backbone_model)\n",
    "    \n",
    "    if DO_REGRESSION:\n",
    "        config.attention_probs_dropout_prob = 0.0\n",
    "        config.hidden_dropout_prob = 0.0\n",
    "        config.num_labels = 1\n",
    "    else:\n",
    "        config.num_labels = CFG.num_labels\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    backbone_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        CFG.backbone_model,\n",
    "        config=config,\n",
    "    )\n",
    "    backbone_model.resize_token_embeddings(len(tokenizer))\n",
    "    return backbone_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_predictions(predictions0):\n",
    "    if DO_REGRESSION:\n",
    "        predictions = predictions0.clip(0, 5).round(0)\n",
    "    else:\n",
    "        predictions = predictions0.argmax(axis=1)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(trainer, tokenized_test, test_data):\n",
    "    y_true = test_data[\"label\"].values\n",
    "    logits = trainer.predict(tokenized_test).predictions\n",
    "    y_pred = post_process_predictions(logits)\n",
    "\n",
    "    score = compute_metrics((y_pred, y_true))[\"qwk\"]\n",
    "    wandb.log({\"QWK\": score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dce18a3eecd474ba2fb2a817cf0be37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4568 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5debc575a34e4a8c91f7a3a71eb873e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2054 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2384e4cfef94ef4b947ce9fdea26d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train, tokenized_valid, tokenized_test = tokenize_data(\n",
    "    train_data, valid_data, test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sweep_config=None):\n",
    "    with wandb.init(config=sweep_config):\n",
    "        sweep_config = wandb.config\n",
    "        seed_everything()\n",
    "\n",
    "        backbone_model = get_model(configure())\n",
    "\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            data_seed=CFG.seed,\n",
    "            dataloader_num_workers=CFG.num_workers,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            fp16=True,\n",
    "            learning_rate=sweep_config.lr,\n",
    "            load_best_model_at_end=True,\n",
    "            logging_first_step=True,\n",
    "            logging_steps=250,\n",
    "            logging_dir=Paths.logging_path,\n",
    "            lr_scheduler_type=sweep_config.lr_scheduler_type,\n",
    "            metric_for_best_model=\"qwk\",\n",
    "            num_train_epochs=sweep_config.num_epochs,\n",
    "            output_dir=Paths.output_path,\n",
    "            optim=\"adamw_torch\",\n",
    "            per_device_eval_batch_size=sweep_config.batch_size,\n",
    "            per_device_train_batch_size=sweep_config.batch_size,\n",
    "            report_to=\"wandb\",\n",
    "            seed=CFG.seed,\n",
    "            save_total_limit=1,\n",
    "            save_strategy=\"epoch\",\n",
    "            weight_decay=sweep_config.weight_decay,\n",
    "            warmup_ratio=sweep_config.warmup_ratio,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=backbone_model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        score_model(trainer, tokenized_test, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uayh872x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_checkpointing: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00047506985383954784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: linear\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.09660615857749676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.019338687399429386\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/ishfar/New Volume/Studies/Projects/Kaggle-Automated-Essay-Scoring/wandb/run-20240613_181314-uayh872x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/uayh872x' target=\"_blank\">noble-sweep-1</a></strong> to <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/uayh872x' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/uayh872x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_scheduler_type' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_checkpointing' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03209647c5f44a0ba725666a967c5eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.4293, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a278981078f14ccb9ea3b848832c6934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7312950491905212, 'eval_qwk': 0.6626908640961982, 'eval_runtime': 6.0628, 'eval_samples_per_second': 338.785, 'eval_steps_per_second': 10.721, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36007c4350684809bede845038e14b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44686359167099, 'eval_qwk': 0.7349368723919223, 'eval_runtime': 6.158, 'eval_samples_per_second': 333.548, 'eval_steps_per_second': 10.555, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829b6088d9c4449f88b3c2fdbb1935eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3670250475406647, 'eval_qwk': 0.8148729032104691, 'eval_runtime': 6.1966, 'eval_samples_per_second': 331.473, 'eval_steps_per_second': 10.49, 'epoch': 2.98}\n",
      "{'train_runtime': 122.1398, 'train_samples_per_second': 112.199, 'train_steps_per_second': 1.744, 'train_loss': 0.7531390884112864, 'epoch': 2.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540f1a79d6d34bcb8dac23dd77013d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac940c1a0edf4fedab1eae31f3ca2a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>QWK</td><td>‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>eval/qwk</td><td>‚ñÅ‚ñÑ‚ñà</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÜ‚ñà</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>QWK</td><td>0.78819</td></tr><tr><td>eval/loss</td><td>0.36703</td></tr><tr><td>eval/qwk</td><td>0.81487</td></tr><tr><td>eval/runtime</td><td>6.1966</td></tr><tr><td>eval/samples_per_second</td><td>331.473</td></tr><tr><td>eval/steps_per_second</td><td>10.49</td></tr><tr><td>total_flos</td><td>896939113463808.0</td></tr><tr><td>train/epoch</td><td>2.98</td></tr><tr><td>train/global_step</td><td>213</td></tr><tr><td>train/grad_norm</td><td>inf</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>7.4293</td></tr><tr><td>train_loss</td><td>0.75314</td></tr><tr><td>train_runtime</td><td>122.1398</td></tr><tr><td>train_samples_per_second</td><td>112.199</td></tr><tr><td>train_steps_per_second</td><td>1.744</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-sweep-1</strong> at: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/uayh872x' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/uayh872x</a><br/> View project at: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240613_181314-uayh872x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o2feec7g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_checkpointing: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0007194249121713805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: linear\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.07441723883852884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.027249254922248597\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/ishfar/New Volume/Studies/Projects/Kaggle-Automated-Essay-Scoring/wandb/run-20240613_181533-o2feec7g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/o2feec7g' target=\"_blank\">whole-sweep-2</a></strong> to <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/o2feec7g' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/o2feec7g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_scheduler_type' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_checkpointing' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5e2069a2a045488a0d292cb05fd1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.4293, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40a2d3030e6467fbe4a8f9a8e4439dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.267929196357727, 'eval_qwk': 0.0, 'eval_runtime': 6.5418, 'eval_samples_per_second': 313.981, 'eval_steps_per_second': 19.719, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366cf0ff5c534e60bbbc5784dcc83b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3124651908874512, 'eval_qwk': 0.0, 'eval_runtime': 6.552, 'eval_samples_per_second': 313.491, 'eval_steps_per_second': 19.689, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3cd95c2c244bcca68524be5f2cd6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2289841175079346, 'eval_qwk': 0.0, 'eval_runtime': 6.4543, 'eval_samples_per_second': 318.236, 'eval_steps_per_second': 19.987, 'epoch': 2.99}\n",
      "{'loss': 1.3705, 'grad_norm': 9.521703720092773, 'learning_rate': 0.00023469044390956621, 'epoch': 3.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89dc62888f74823b7400efdeed547fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2290771007537842, 'eval_qwk': 0.0, 'eval_runtime': 6.4997, 'eval_samples_per_second': 316.015, 'eval_steps_per_second': 19.847, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb715df58af486e9b801a4c1ef67804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2292695045471191, 'eval_qwk': 0.0, 'eval_runtime': 6.5284, 'eval_samples_per_second': 314.624, 'eval_steps_per_second': 19.76, 'epoch': 4.97}\n",
      "{'train_runtime': 280.4352, 'train_samples_per_second': 81.445, 'train_steps_per_second': 1.266, 'train_loss': 1.3453393586924378, 'epoch': 4.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98843ed8ba7044c3a6b8a7ac48d6916e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56386570339449f809c9f560e23026c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>QWK</td><td>‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/qwk</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñá‚ñà‚ñÅ‚ñÑ‚ñÜ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÇ‚ñÅ‚ñà‚ñÖ‚ñÉ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÇ‚ñÅ‚ñà‚ñÖ‚ñÉ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td> ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ‚ñà</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>QWK</td><td>0.0</td></tr><tr><td>eval/loss</td><td>1.22927</td></tr><tr><td>eval/qwk</td><td>0.0</td></tr><tr><td>eval/runtime</td><td>6.5284</td></tr><tr><td>eval/samples_per_second</td><td>314.624</td></tr><tr><td>eval/steps_per_second</td><td>19.76</td></tr><tr><td>total_flos</td><td>1494547194937344.0</td></tr><tr><td>train/epoch</td><td>4.97</td></tr><tr><td>train/global_step</td><td>355</td></tr><tr><td>train/grad_norm</td><td>9.5217</td></tr><tr><td>train/learning_rate</td><td>0.00023</td></tr><tr><td>train/loss</td><td>1.3705</td></tr><tr><td>train_loss</td><td>1.34534</td></tr><tr><td>train_runtime</td><td>280.4352</td></tr><tr><td>train_samples_per_second</td><td>81.445</td></tr><tr><td>train_steps_per_second</td><td>1.266</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-2</strong> at: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/o2feec7g' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/o2feec7g</a><br/> View project at: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240613_181533-o2feec7g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: au9eykhx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_checkpointing: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005739866427008236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: cosine\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.09401645418933266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.04653827753363589\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/ishfar/New Volume/Studies/Projects/Kaggle-Automated-Essay-Scoring/wandb/run-20240613_182035-au9eykhx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/au9eykhx' target=\"_blank\">glamorous-sweep-3</a></strong> to <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/sweeps/norrpezc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/au9eykhx' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/au9eykhx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_scheduler_type' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gradient_checkpointing' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad4e396b4624c3b9b7c9bd33486dc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/858 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.0427, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.0}\n",
      "{'loss': 1.361, 'grad_norm': 3.515922784805298, 'learning_rate': 0.0005117350193690799, 'epoch': 0.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f256a529a54a2396d418334b156cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.244022011756897, 'eval_qwk': 0.0, 'eval_runtime': 6.5348, 'eval_samples_per_second': 314.315, 'eval_steps_per_second': 19.74, 'epoch': 1.0}\n",
      "{'loss': 1.2449, 'grad_norm': 5.379490852355957, 'learning_rate': 0.0002551485520621797, 'epoch': 1.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e64691fa6d142d381314a2f2cbe17c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2349462509155273, 'eval_qwk': 0.0, 'eval_runtime': 6.6247, 'eval_samples_per_second': 310.05, 'eval_steps_per_second': 19.472, 'epoch': 2.0}\n",
      "{'loss': 1.2411, 'grad_norm': 2.4494705200195312, 'learning_rate': 2.8421273517776134e-05, 'epoch': 2.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c2443843624cac8fe1ba9824a86d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2291325330734253, 'eval_qwk': 0.0, 'eval_runtime': 6.4925, 'eval_samples_per_second': 316.366, 'eval_steps_per_second': 19.869, 'epoch': 3.0}\n",
      "{'train_runtime': 136.4966, 'train_samples_per_second': 100.398, 'train_steps_per_second': 6.286, 'train_loss': 1.2802293094999584, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b5136c1a9744d188f39e9fc49d8fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8905295c20e84d02ac0a569194ac22fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>QWK</td><td>‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÑ‚ñÅ</td></tr><tr><td>eval/qwk</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÉ‚ñà‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÜ‚ñÅ‚ñà</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÜ‚ñÅ‚ñà</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td> ‚ñÑ‚ñà‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ‚ñà‚ñÑ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>QWK</td><td>0.0</td></tr><tr><td>eval/loss</td><td>1.22913</td></tr><tr><td>eval/qwk</td><td>0.0</td></tr><tr><td>eval/runtime</td><td>6.4925</td></tr><tr><td>eval/samples_per_second</td><td>316.366</td></tr><tr><td>eval/steps_per_second</td><td>19.869</td></tr><tr><td>total_flos</td><td>902736017252352.0</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>858</td></tr><tr><td>train/grad_norm</td><td>2.44947</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.2411</td></tr><tr><td>train_loss</td><td>1.28023</td></tr><tr><td>train_runtime</td><td>136.4966</td></tr><tr><td>train_samples_per_second</td><td>100.398</td></tr><tr><td>train_steps_per_second</td><td>6.286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-sweep-3</strong> at: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/au9eykhx' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0/runs/au9eykhx</a><br/> View project at: <a href='https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0' target=\"_blank\">https://wandb.ai/laplacesdemon43/Kaggle_ASE_2.0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240613_182035-au9eykhx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, main, count=3, project=WANDB_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
